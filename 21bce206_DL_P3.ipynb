{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-02T03:59:33.888204Z","iopub.status.busy":"2024-02-02T03:59:33.887727Z","iopub.status.idle":"2024-02-02T03:59:37.850021Z","shell.execute_reply":"2024-02-02T03:59:37.849357Z","shell.execute_reply.started":"2024-02-02T03:59:33.888148Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torchvision import datasets\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import ToTensor\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-02T03:59:42.142469Z","iopub.status.busy":"2024-02-02T03:59:42.141964Z","iopub.status.idle":"2024-02-02T03:59:42.147215Z","shell.execute_reply":"2024-02-02T03:59:42.146534Z","shell.execute_reply.started":"2024-02-02T03:59:42.142437Z"},"trusted":true},"outputs":[],"source":["if torch.cuda.is_available():\n","    device=torch.device(type=\"cuda\",index=0)\n","else:\n","    device=torch.device(type=\"cpu\",index=0)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-02T03:59:43.145964Z","iopub.status.busy":"2024-02-02T03:59:43.145541Z","iopub.status.idle":"2024-02-02T03:59:43.888059Z","shell.execute_reply":"2024-02-02T03:59:43.886462Z","shell.execute_reply.started":"2024-02-02T03:59:43.145935Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 220643909.61it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 73638719.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 61118743.29it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 11862097.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n","\n"]}],"source":["train_dataset=datasets.MNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","test_dataset=datasets.MNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-02T03:59:49.229945Z","iopub.status.busy":"2024-02-02T03:59:49.229581Z","iopub.status.idle":"2024-02-02T03:59:49.235977Z","shell.execute_reply":"2024-02-02T03:59:49.235242Z","shell.execute_reply.started":"2024-02-02T03:59:49.229919Z"},"trusted":true},"outputs":[],"source":["batch_size=64\n","\n","train_dl=DataLoader(\n","    dataset=train_dataset,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","test_dl=DataLoader(\n","    dataset=test_dataset,\n","    batch_size=batch_size, \n","    shuffle=True\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch No: 1\n","\n","Batch: 1 / 938 Running Loss: 2.68 Running Accuracy: 9.38\n","\n","Batch: 101 / 938 Running Loss: 0.78 Running Accuracy: 83.88\n","\n","Batch: 201 / 938 Running Loss: 0.62 Running Accuracy: 88.5\n","\n","Batch: 301 / 938 Running Loss: 0.55 Running Accuracy: 90.05\n","\n","Batch: 401 / 938 Running Loss: 0.49 Running Accuracy: 91.13\n","\n","Batch: 501 / 938 Running Loss: 0.46 Running Accuracy: 91.74\n","\n","Batch: 601 / 938 Running Loss: 0.43 Running Accuracy: 92.24\n","\n","Batch: 701 / 938 Running Loss: 0.41 Running Accuracy: 92.61\n","\n","Batch: 801 / 938 Running Loss: 0.39 Running Accuracy: 92.84\n","\n","Batch: 901 / 938 Running Loss: 0.37 Running Accuracy: 93.18\n","\n","Batch: 1 / 157 Running Loss: 0.2 Running Accuracy: 93.75\n","\n","Batch: 101 / 157 Running Loss: 0.17 Running Accuracy: 96.67\n","\n","Training: Epoch Loss: 0.36 Epoch Accuracy: 93.27\n","\n","Inference: Epoch Loss: 0.17 Epoch Accuracy: 96.64\n","\n","--------------------------------------------------\n","\n","Epoch No: 2\n","\n","Batch: 1 / 938 Running Loss: 0.12 Running Accuracy: 98.44\n","\n","Batch: 101 / 938 Running Loss: 0.19 Running Accuracy: 96.47\n","\n","Batch: 201 / 938 Running Loss: 0.19 Running Accuracy: 96.16\n","\n","Batch: 301 / 938 Running Loss: 0.19 Running Accuracy: 96.21\n","\n","Batch: 401 / 938 Running Loss: 0.19 Running Accuracy: 96.19\n","\n","Batch: 501 / 938 Running Loss: 0.18 Running Accuracy: 96.18\n","\n","Batch: 601 / 938 Running Loss: 0.18 Running Accuracy: 96.21\n","\n","Batch: 701 / 938 Running Loss: 0.18 Running Accuracy: 96.25\n","\n","Batch: 801 / 938 Running Loss: 0.17 Running Accuracy: 96.32\n","\n","Batch: 901 / 938 Running Loss: 0.17 Running Accuracy: 96.37\n","\n","Batch: 1 / 157 Running Loss: 0.11 Running Accuracy: 96.88\n","\n","Batch: 101 / 157 Running Loss: 0.11 Running Accuracy: 97.31\n","\n","Training: Epoch Loss: 0.17 Epoch Accuracy: 96.36\n","\n","Inference: Epoch Loss: 0.11 Epoch Accuracy: 97.48\n","\n","--------------------------------------------------\n","\n","Epoch No: 3\n","\n","Batch: 1 / 938 Running Loss: 0.14 Running Accuracy: 98.44\n","\n","Batch: 101 / 938 Running Loss: 0.12 Running Accuracy: 97.52\n","\n","Batch: 201 / 938 Running Loss: 0.12 Running Accuracy: 97.61\n","\n","Batch: 301 / 938 Running Loss: 0.12 Running Accuracy: 97.45\n","\n","Batch: 401 / 938 Running Loss: 0.12 Running Accuracy: 97.45\n","\n","Batch: 501 / 938 Running Loss: 0.12 Running Accuracy: 97.41\n","\n","Batch: 601 / 938 Running Loss: 0.12 Running Accuracy: 97.32\n","\n","Batch: 701 / 938 Running Loss: 0.12 Running Accuracy: 97.31\n","\n","Batch: 801 / 938 Running Loss: 0.12 Running Accuracy: 97.25\n","\n","Batch: 901 / 938 Running Loss: 0.12 Running Accuracy: 97.25\n","\n","Batch: 1 / 157 Running Loss: 0.05 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.08 Running Accuracy: 97.88\n","\n","Training: Epoch Loss: 0.12 Epoch Accuracy: 97.23\n","\n","Inference: Epoch Loss: 0.08 Epoch Accuracy: 97.81\n","\n","--------------------------------------------------\n","\n","Epoch No: 4\n","\n","Batch: 1 / 938 Running Loss: 0.1 Running Accuracy: 96.88\n","\n","Batch: 101 / 938 Running Loss: 0.09 Running Accuracy: 97.99\n","\n","Batch: 201 / 938 Running Loss: 0.09 Running Accuracy: 97.92\n","\n","Batch: 301 / 938 Running Loss: 0.09 Running Accuracy: 97.88\n","\n","Batch: 401 / 938 Running Loss: 0.09 Running Accuracy: 97.79\n","\n","Batch: 501 / 938 Running Loss: 0.09 Running Accuracy: 97.78\n","\n","Batch: 601 / 938 Running Loss: 0.09 Running Accuracy: 97.82\n","\n","Batch: 701 / 938 Running Loss: 0.09 Running Accuracy: 97.78\n","\n","Batch: 801 / 938 Running Loss: 0.09 Running Accuracy: 97.8\n","\n","Batch: 901 / 938 Running Loss: 0.09 Running Accuracy: 97.8\n","\n","Batch: 1 / 157 Running Loss: 0.03 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.07 Running Accuracy: 97.97\n","\n","Training: Epoch Loss: 0.09 Epoch Accuracy: 97.78\n","\n","Inference: Epoch Loss: 0.07 Epoch Accuracy: 97.94\n","\n","--------------------------------------------------\n","\n","Epoch No: 5\n","\n","Batch: 1 / 938 Running Loss: 0.02 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.07 Running Accuracy: 98.44\n","\n","Batch: 201 / 938 Running Loss: 0.07 Running Accuracy: 98.3\n","\n","Batch: 301 / 938 Running Loss: 0.07 Running Accuracy: 98.3\n","\n","Batch: 401 / 938 Running Loss: 0.07 Running Accuracy: 98.22\n","\n","Batch: 501 / 938 Running Loss: 0.08 Running Accuracy: 98.15\n","\n","Batch: 601 / 938 Running Loss: 0.07 Running Accuracy: 98.18\n","\n","Batch: 701 / 938 Running Loss: 0.07 Running Accuracy: 98.13\n","\n","Batch: 801 / 938 Running Loss: 0.07 Running Accuracy: 98.12\n","\n","Batch: 901 / 938 Running Loss: 0.07 Running Accuracy: 98.11\n","\n","Batch: 1 / 157 Running Loss: 0.19 Running Accuracy: 95.31\n","\n","Batch: 101 / 157 Running Loss: 0.07 Running Accuracy: 98.13\n","\n","Training: Epoch Loss: 0.07 Epoch Accuracy: 98.13\n","\n","Inference: Epoch Loss: 0.07 Epoch Accuracy: 98.17\n","\n","--------------------------------------------------\n","\n","Epoch No: 6\n","\n","Batch: 1 / 938 Running Loss: 0.02 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.06 Running Accuracy: 98.31\n","\n","Batch: 201 / 938 Running Loss: 0.06 Running Accuracy: 98.44\n","\n","Batch: 301 / 938 Running Loss: 0.06 Running Accuracy: 98.32\n","\n","Batch: 401 / 938 Running Loss: 0.06 Running Accuracy: 98.36\n","\n","Batch: 501 / 938 Running Loss: 0.06 Running Accuracy: 98.31\n","\n","Batch: 601 / 938 Running Loss: 0.06 Running Accuracy: 98.28\n","\n","Batch: 701 / 938 Running Loss: 0.06 Running Accuracy: 98.28\n","\n","Batch: 801 / 938 Running Loss: 0.06 Running Accuracy: 98.34\n","\n","Batch: 901 / 938 Running Loss: 0.06 Running Accuracy: 98.34\n","\n","Batch: 1 / 157 Running Loss: 0.01 Running Accuracy: 100.0\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.24\n","\n","Training: Epoch Loss: 0.06 Epoch Accuracy: 98.34\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.21\n","\n","--------------------------------------------------\n","\n","Epoch No: 7\n","\n","Batch: 1 / 938 Running Loss: 0.02 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.05 Running Accuracy: 98.81\n","\n","Batch: 201 / 938 Running Loss: 0.05 Running Accuracy: 98.78\n","\n","Batch: 301 / 938 Running Loss: 0.05 Running Accuracy: 98.73\n","\n","Batch: 401 / 938 Running Loss: 0.05 Running Accuracy: 98.68\n","\n","Batch: 501 / 938 Running Loss: 0.05 Running Accuracy: 98.75\n","\n","Batch: 601 / 938 Running Loss: 0.05 Running Accuracy: 98.73\n","\n","Batch: 701 / 938 Running Loss: 0.05 Running Accuracy: 98.7\n","\n","Batch: 801 / 938 Running Loss: 0.05 Running Accuracy: 98.66\n","\n","Batch: 901 / 938 Running Loss: 0.05 Running Accuracy: 98.62\n","\n","Batch: 1 / 157 Running Loss: 0.03 Running Accuracy: 100.0\n","\n","Batch: 101 / 157 Running Loss: 0.07 Running Accuracy: 98.08\n","\n","Training: Epoch Loss: 0.05 Epoch Accuracy: 98.61\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.18\n","\n","--------------------------------------------------\n","\n","Epoch No: 8\n","\n","Batch: 1 / 938 Running Loss: 0.04 Running Accuracy: 98.44\n","\n","Batch: 101 / 938 Running Loss: 0.04 Running Accuracy: 98.93\n","\n","Batch: 201 / 938 Running Loss: 0.04 Running Accuracy: 99.02\n","\n","Batch: 301 / 938 Running Loss: 0.04 Running Accuracy: 98.95\n","\n","Batch: 401 / 938 Running Loss: 0.05 Running Accuracy: 98.81\n","\n","Batch: 501 / 938 Running Loss: 0.05 Running Accuracy: 98.71\n","\n","Batch: 601 / 938 Running Loss: 0.05 Running Accuracy: 98.72\n","\n","Batch: 701 / 938 Running Loss: 0.05 Running Accuracy: 98.74\n","\n","Batch: 801 / 938 Running Loss: 0.05 Running Accuracy: 98.69\n","\n","Batch: 901 / 938 Running Loss: 0.05 Running Accuracy: 98.62\n","\n","Batch: 1 / 157 Running Loss: 0.06 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.28\n","\n","Training: Epoch Loss: 0.05 Epoch Accuracy: 98.64\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.29\n","\n","--------------------------------------------------\n","\n","Epoch No: 9\n","\n","Batch: 1 / 938 Running Loss: 0.04 Running Accuracy: 98.44\n","\n","Batch: 101 / 938 Running Loss: 0.03 Running Accuracy: 99.21\n","\n","Batch: 201 / 938 Running Loss: 0.04 Running Accuracy: 99.07\n","\n","Batch: 301 / 938 Running Loss: 0.04 Running Accuracy: 98.92\n","\n","Batch: 401 / 938 Running Loss: 0.04 Running Accuracy: 98.95\n","\n","Batch: 501 / 938 Running Loss: 0.04 Running Accuracy: 98.9\n","\n","Batch: 601 / 938 Running Loss: 0.04 Running Accuracy: 98.92\n","\n","Batch: 701 / 938 Running Loss: 0.04 Running Accuracy: 98.93\n","\n","Batch: 801 / 938 Running Loss: 0.04 Running Accuracy: 98.91\n","\n","Batch: 901 / 938 Running Loss: 0.04 Running Accuracy: 98.91\n","\n","Batch: 1 / 157 Running Loss: 0.01 Running Accuracy: 100.0\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.19\n","\n","Training: Epoch Loss: 0.04 Epoch Accuracy: 98.92\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.28\n","\n","--------------------------------------------------\n","\n","Epoch No: 10\n","\n","Batch: 1 / 938 Running Loss: 0.05 Running Accuracy: 98.44\n","\n","Batch: 101 / 938 Running Loss: 0.03 Running Accuracy: 99.01\n","\n","Batch: 201 / 938 Running Loss: 0.03 Running Accuracy: 98.97\n","\n","Batch: 301 / 938 Running Loss: 0.03 Running Accuracy: 99.02\n","\n","Batch: 401 / 938 Running Loss: 0.03 Running Accuracy: 99.05\n","Batch: 501 / 938 Running Loss: 0.03 Running Accuracy: 99.04\n","\n","Batch: 601 / 938 Running Loss: 0.03 Running Accuracy: 99.0\n","\n","Batch: 701 / 938 Running Loss: 0.03 Running Accuracy: 98.99\n","\n","Batch: 801 / 938 Running Loss: 0.03 Running Accuracy: 98.99\n","\n","Batch: 901 / 938 Running Loss: 0.03 Running Accuracy: 98.99\n","\n","Batch: 1 / 157 Running Loss: 0.04 Running Accuracy: 96.88\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.34\n","\n","Training: Epoch Loss: 0.03 Epoch Accuracy: 98.99\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.33\n","\n","--------------------------------------------------\n","\n","Epoch No: 11\n","\n","Batch: 1 / 938 Running Loss: 0.1 Running Accuracy: 95.31\n","\n","Batch: 101 / 938 Running Loss: 0.03 Running Accuracy: 99.16\n","\n","Batch: 201 / 938 Running Loss: 0.03 Running Accuracy: 99.23\n","\n","Batch: 301 / 938 Running Loss: 0.03 Running Accuracy: 99.26\n","\n","Batch: 401 / 938 Running Loss: 0.03 Running Accuracy: 99.26\n","\n","Batch: 501 / 938 Running Loss: 0.03 Running Accuracy: 99.24\n","\n","Batch: 601 / 938 Running Loss: 0.03 Running Accuracy: 99.19\n","\n","Batch: 701 / 938 Running Loss: 0.03 Running Accuracy: 99.18\n","\n","Batch: 801 / 938 Running Loss: 0.03 Running Accuracy: 99.15\n","\n","Batch: 901 / 938 Running Loss: 0.03 Running Accuracy: 99.11\n","\n","Batch: 1 / 157 Running Loss: 0.09 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.27\n","\n","Training: Epoch Loss: 0.03 Epoch Accuracy: 99.11\n","\n","Inference: Epoch Loss: 0.05 Epoch Accuracy: 98.4\n","\n","--------------------------------------------------\n","\n","Epoch No: 12\n","\n","Batch: 1 / 938 Running Loss: 0.04 Running Accuracy: 96.88\n","\n","Batch: 101 / 938 Running Loss: 0.03 Running Accuracy: 99.27\n","\n","Batch: 201 / 938 Running Loss: 0.03 Running Accuracy: 99.23\n","\n","Batch: 301 / 938 Running Loss: 0.03 Running Accuracy: 99.2\n","\n","Batch: 401 / 938 Running Loss: 0.03 Running Accuracy: 99.2\n","\n","Batch: 501 / 938 Running Loss: 0.03 Running Accuracy: 99.16\n","\n","Batch: 601 / 938 Running Loss: 0.03 Running Accuracy: 99.15\n","\n","Batch: 701 / 938 Running Loss: 0.03 Running Accuracy: 99.15\n","\n","Batch: 801 / 938 Running Loss: 0.03 Running Accuracy: 99.16\n","\n","Batch: 901 / 938 Running Loss: 0.03 Running Accuracy: 99.16\n","\n","Batch: 1 / 157 Running Loss: 0.05 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.47\n","\n","Training: Epoch Loss: 0.03 Epoch Accuracy: 99.17\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.25\n","\n","--------------------------------------------------\n","\n","Epoch No: 13\n","\n","Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.02 Running Accuracy: 99.55\n","\n","Batch: 201 / 938 Running Loss: 0.02 Running Accuracy: 99.48\n","\n","Batch: 301 / 938 Running Loss: 0.02 Running Accuracy: 99.46\n","\n","Batch: 401 / 938 Running Loss: 0.02 Running Accuracy: 99.46\n","\n","Batch: 501 / 938 Running Loss: 0.02 Running Accuracy: 99.43\n","\n","Batch: 601 / 938 Running Loss: 0.02 Running Accuracy: 99.42\n","\n","Batch: 701 / 938 Running Loss: 0.02 Running Accuracy: 99.4\n","\n","Batch: 801 / 938 Running Loss: 0.02 Running Accuracy: 99.38\n","\n","Batch: 901 / 938 Running Loss: 0.02 Running Accuracy: 99.38\n","\n","Batch: 1 / 157 Running Loss: 0.03 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.33\n","\n","Training: Epoch Loss: 0.02 Epoch Accuracy: 99.38\n","\n","Inference: Epoch Loss: 0.05 Epoch Accuracy: 98.44\n","\n","--------------------------------------------------\n","\n","Epoch No: 14\n","\n","Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.02 Running Accuracy: 99.49\n","\n","Batch: 201 / 938 Running Loss: 0.02 Running Accuracy: 99.52\n","\n","Batch: 301 / 938 Running Loss: 0.02 Running Accuracy: 99.5\n","\n","Batch: 401 / 938 Running Loss: 0.02 Running Accuracy: 99.43\n","\n","Batch: 501 / 938 Running Loss: 0.02 Running Accuracy: 99.41\n","\n","Batch: 601 / 938 Running Loss: 0.02 Running Accuracy: 99.39\n","\n","Batch: 701 / 938 Running Loss: 0.02 Running Accuracy: 99.38\n","\n","Batch: 801 / 938 Running Loss: 0.02 Running Accuracy: 99.37\n","\n","Batch: 901 / 938 Running Loss: 0.02 Running Accuracy: 99.39\n","\n","Batch: 1 / 157 Running Loss: 0.03 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.39\n","\n","Training: Epoch Loss: 0.02 Epoch Accuracy: 99.39\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.27\n","\n","--------------------------------------------------\n","\n","Epoch No: 15\n","\n","Batch: 1 / 938 Running Loss: 0.03 Running Accuracy: 98.44\n","\n","Batch: 101 / 938 Running Loss: 0.03 Running Accuracy: 99.16\n","\n","Batch: 201 / 938 Running Loss: 0.03 Running Accuracy: 99.21\n","\n","Batch: 301 / 938 Running Loss: 0.03 Running Accuracy: 99.2\n","\n","Batch: 401 / 938 Running Loss: 0.03 Running Accuracy: 99.24\n","\n","Batch: 501 / 938 Running Loss: 0.02 Running Accuracy: 99.3\n","\n","Batch: 601 / 938 Running Loss: 0.02 Running Accuracy: 99.3\n","\n","Batch: 701 / 938 Running Loss: 0.02 Running Accuracy: 99.32\n","\n","Batch: 801 / 938 Running Loss: 0.02 Running Accuracy: 99.33\n","\n","Batch: 901 / 938 Running Loss: 0.02 Running Accuracy: 99.33\n","\n","Batch: 1 / 157 Running Loss: 0.11 Running Accuracy: 96.88\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.25\n","\n","Training: Epoch Loss: 0.02 Epoch Accuracy: 99.31\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.31\n","\n","--------------------------------------------------\n","\n","Epoch No: 16\n","\n","Batch: 1 / 938 Running Loss: 0.03 Running Accuracy: 98.44\n","\n","Batch: 101 / 938 Running Loss: 0.02 Running Accuracy: 99.37\n","\n","Batch: 201 / 938 Running Loss: 0.02 Running Accuracy: 99.46\n","\n","Batch: 301 / 938 Running Loss: 0.02 Running Accuracy: 99.5\n","\n","Batch: 401 / 938 Running Loss: 0.02 Running Accuracy: 99.49\n","\n","Batch: 501 / 938 Running Loss: 0.02 Running Accuracy: 99.47\n","\n","Batch: 601 / 938 Running Loss: 0.02 Running Accuracy: 99.48\n","\n","Batch: 701 / 938 Running Loss: 0.02 Running Accuracy: 99.45\n","\n","Batch: 801 / 938 Running Loss: 0.02 Running Accuracy: 99.45\n","\n","Batch: 901 / 938 Running Loss: 0.02 Running Accuracy: 99.44\n","\n","Batch: 1 / 157 Running Loss: 0.04 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.48\n","\n","Training: Epoch Loss: 0.02 Epoch Accuracy: 99.43\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.49\n","\n","--------------------------------------------------\n","\n","Epoch No: 17\n","\n","Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.58\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.6\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.6\n","\n","Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.55\n","\n","Batch: 501 / 938 Running Loss: 0.02 Running Accuracy: 99.5\n","\n","Batch: 601 / 938 Running Loss: 0.02 Running Accuracy: 99.47\n","\n","Batch: 701 / 938 Running Loss: 0.02 Running Accuracy: 99.48\n","\n","Batch: 801 / 938 Running Loss: 0.02 Running Accuracy: 99.48\n","\n","Batch: 901 / 938 Running Loss: 0.02 Running Accuracy: 99.47\n","\n","Batch: 1 / 157 Running Loss: 0.01 Running Accuracy: 100.0\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.42\n","\n","Training: Epoch Loss: 0.02 Epoch Accuracy: 99.48\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.36\n","\n","--------------------------------------------------\n","\n","Epoch No: 18\n","\n","Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.78\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.67\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.55\n","\n","Batch: 401 / 938 Running Loss: 0.02 Running Accuracy: 99.55\n","\n","Batch: 501 / 938 Running Loss: 0.02 Running Accuracy: 99.55\n","\n","Batch: 601 / 938 Running Loss: 0.02 Running Accuracy: 99.57\n","\n","Batch: 701 / 938 Running Loss: 0.02 Running Accuracy: 99.56\n","\n","Batch: 801 / 938 Running Loss: 0.02 Running Accuracy: 99.56\n","\n","Batch: 901 / 938 Running Loss: 0.02 Running Accuracy: 99.56\n","\n","Batch: 1 / 157 Running Loss: 0.0 Running Accuracy: 100.0\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.44\n","\n","Training: Epoch Loss: 0.02 Epoch Accuracy: 99.56\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.48\n","\n","--------------------------------------------------\n","\n","Epoch No: 19\n","\n","Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.57\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.53\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.54\n","\n","Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.55\n","\n","Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.56\n","\n","Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.55\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.53\n","\n","Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.53\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.53\n","Batch: 1 / 157 Running Loss: 0.02 Running Accuracy: 100.0\n","\n","Batch: 101 / 157 Running Loss: 0.05 Running Accuracy: 98.67\n","\n","Training: Epoch Loss: 0.01 Epoch Accuracy: 99.54\n","\n","Inference: Epoch Loss: 0.05 Epoch Accuracy: 98.54\n","\n","--------------------------------------------------\n","\n","Epoch No: 20\n","\n","Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.57\n","\n","Batch: 201 / 938 Running Loss: 0.02 Running Accuracy: 99.54\n","\n","Batch: 301 / 938 Running Loss: 0.02 Running Accuracy: 99.54\n","\n","Batch: 401 / 938 Running Loss: 0.02 Running Accuracy: 99.54\n","\n","Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.58\n","\n","Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.58\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.58\n","\n","Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.56\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.56\n","\n","Batch: 1 / 157 Running Loss: 0.2 Running Accuracy: 95.31\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.33\n","\n","Training: Epoch Loss: 0.02 Epoch Accuracy: 99.55\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.29\n","\n","--------------------------------------------------\n","\n","Epoch No: 21\n","\n","Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.02 Running Accuracy: 99.52\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.56\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.53\n","\n","Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.56\n","\n","Batch: 501 / 938 Running Loss: 0.02 Running Accuracy: 99.53\n","\n","Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.55\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.55\n","\n","Batch: 801 / 938 Running Loss: 0.02 Running Accuracy: 99.55\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.56\n","\n","Batch: 1 / 157 Running Loss: 0.08 Running Accuracy: 96.88\n","\n","Batch: 101 / 157 Running Loss: 0.07 Running Accuracy: 98.22\n","\n","Training: Epoch Loss: 0.01 Epoch Accuracy: 99.56\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.26\n","\n","--------------------------------------------------\n","\n","Epoch No: 22\n","\n","Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.55\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.6\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.56\n","\n","Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.6\n","\n","Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.6\n","\n","Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.62\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.63\n","\n","Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.65\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.64\n","\n","Batch: 1 / 157 Running Loss: 0.06 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.44\n","\n","Training: Epoch Loss: 0.01 Epoch Accuracy: 99.63\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.35\n","\n","--------------------------------------------------\n","\n","Epoch No: 23\n","\n","Batch: 1 / 938 Running Loss: 0.04 Running Accuracy: 98.44\n","\n","Batch: 101 / 938 Running Loss: 0.02 Running Accuracy: 99.55\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.62\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.63\n","\n","Batch: 401 / 938 Running Loss: 0.02 Running Accuracy: 99.59\n","\n","Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.58\n","\n","Batch: 601 / 938 Running Loss: 0.02 Running Accuracy: 99.58\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.58\n","\n","Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.59\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.6\n","\n","Batch: 1 / 157 Running Loss: 0.01 Running Accuracy: 100.0\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.24\n","\n","Training: Epoch Loss: 0.01 Epoch Accuracy: 99.6\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.36\n","\n","--------------------------------------------------\n","\n","Epoch No: 24\n","\n","Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.92\n","\n","Batch: 201 / 938 Running Loss: 0.0 Running Accuracy: 99.91\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.83\n","\n","Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.79\n","\n","Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.75\n","\n","Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.75\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.74\n","\n","Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.72\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.72\n","\n","Batch: 1 / 157 Running Loss: 0.01 Running Accuracy: 100.0\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.24\n","\n","Training: Epoch Loss: 0.01 Epoch Accuracy: 99.7\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.3\n","\n","--------------------------------------------------\n","\n","Epoch No: 25\n","\n","Batch: 1 / 938 Running Loss: 0.02 Running Accuracy: 98.44\n","\n","Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.68\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.67\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.7\n","\n","Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.7\n","\n","Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.67\n","\n","Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.66\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.67\n","\n","Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.67\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.67\n","\n","Batch: 1 / 157 Running Loss: 0.08 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.56\n","\n","Training: Epoch Loss: 0.01 Epoch Accuracy: 99.67\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.48\n","\n","--------------------------------------------------\n","\n","Epoch No: 26\n","\n","Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.71\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.68\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.67\n","\n","Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.69\n","\n","Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.7\n","\n","Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.71\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.7\n","\n","Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.7\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.69\n","\n","Batch: 1 / 157 Running Loss: 0.17 Running Accuracy: 95.31\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.51\n","\n","Training: Epoch Loss: 0.01 Epoch Accuracy: 99.68\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.57\n","\n","--------------------------------------------------\n","\n","Epoch No: 27\n","\n","Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.72\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.66\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.64\n","\n","Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.66\n","\n","Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.66\n","\n","Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.69\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.71\n","\n","Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.71\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.71\n","\n","Batch: 1 / 157 Running Loss: 0.1 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.53\n","\n","Training: Epoch Loss: 0.01 Epoch Accuracy: 99.71\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.47\n","\n","--------------------------------------------------\n","\n","Epoch No: 28\n","\n","Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.81\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.8\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.8\n","\n","Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.8\n","\n","Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.8\n","\n","Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.81\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.79\n","\n","Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.77\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.76\n","\n","Batch: 1 / 157 Running Loss: 0.02 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.05 Running Accuracy: 98.64\n","\n","Training: Epoch Loss: 0.01 Epoch Accuracy: 99.76\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.5\n","\n","--------------------------------------------------\n","\n","Epoch No: 29\n","\n","Batch: 1 / 938 Running Loss: 0.0 Running Accuracy: 100.0\n","Batch: 101 / 938 Running Loss: 0.02 Running Accuracy: 99.58\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.65\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.64\n","\n","Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.66\n","\n","Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.69\n","\n","Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.7\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.7\n","\n","Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.69\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.68\n","\n","Batch: 1 / 157 Running Loss: 0.13 Running Accuracy: 96.88\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.56\n","\n","Training: Epoch Loss: 0.01 Epoch Accuracy: 99.69\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.57\n","\n","--------------------------------------------------\n","\n","Epoch No: 30\n","\n","Batch: 1 / 938 Running Loss: 0.01 Running Accuracy: 100.0\n","\n","Batch: 101 / 938 Running Loss: 0.01 Running Accuracy: 99.83\n","\n","Batch: 201 / 938 Running Loss: 0.01 Running Accuracy: 99.83\n","\n","Batch: 301 / 938 Running Loss: 0.01 Running Accuracy: 99.81\n","\n","Batch: 401 / 938 Running Loss: 0.01 Running Accuracy: 99.81\n","\n","Batch: 501 / 938 Running Loss: 0.01 Running Accuracy: 99.77\n","\n","Batch: 601 / 938 Running Loss: 0.01 Running Accuracy: 99.76\n","\n","Batch: 701 / 938 Running Loss: 0.01 Running Accuracy: 99.77\n","\n","Batch: 801 / 938 Running Loss: 0.01 Running Accuracy: 99.78\n","\n","Batch: 901 / 938 Running Loss: 0.01 Running Accuracy: 99.77\n","\n","Batch: 1 / 157 Running Loss: 0.03 Running Accuracy: 98.44\n","\n","Batch: 101 / 157 Running Loss: 0.06 Running Accuracy: 98.58\n","\n","Training: Epoch Loss: 0.01 Epoch Accuracy: 99.77\n","\n","Inference: Epoch Loss: 0.06 Epoch Accuracy: 98.58\n","\n","--------------------------------------------------\n"]}],"source":["class MNISTNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.inh1=nn.Linear(in_features=784, out_features=512)\n","        self.relu=nn.ReLU()\n","        self.bn1=nn.BatchNorm1d(num_features=512)\n","        self.h2=nn.Linear(in_features=512, out_features=256)\n","        self.bn2=nn.BatchNorm1d(num_features=256)\n","        self.h3=nn.Linear(in_features=256, out_features=128)\n","        self.bn3=nn.BatchNorm1d(num_features=128)\n","        self.h4=nn.Linear(in_features=128, out_features=64)\n","        self.bn4=nn.BatchNorm1d(num_features=64)\n","        self.h5=nn.Linear(in_features=64, out_features=32)\n","        self.bn5=nn.BatchNorm1d(num_features=32)\n","        self.output=nn.Linear(in_features=32, out_features=10)\n","        self.bn6=nn.BatchNorm1d(num_features=10)\n","        \n","    def forward(self,x):\n","        x=self.inh1(x)\n","        x=self.bn1(x)\n","        x=self.relu(x)\n","        x=self.h2(x)\n","        x=self.bn2(x)\n","        x=self.relu(x)\n","        x=self.h3(x)\n","        x=self.bn3(x)\n","        x=self.relu(x)\n","        x=self.h4(x)\n","        x=self.bn4(x)\n","        x=self.relu(x)\n","        x=self.h5(x)\n","        x=self.bn5(x)\n","        x=self.relu(x)\n","        x=self.output(x)\n","        output=self.bn6(x)\n","        return output\n","    \n","#using batch normalization before relu: Reduces internal covariate shif, Faster convergence, help avoid vanishing or exploding gradients\n","#after relu: Sometimes gives better accuracy by allowing the network to learn from negative activations.\n","\n","def train_one_epoch(dataloader, model,loss_fn, optimizer):\n","    model.train()\n","    track_loss=0\n","    num_correct=0\n","    for i, (imgs, labels) in enumerate(dataloader):\n","        imgs=torch.reshape(imgs,shape=[-1,784]).to(device)\n","        labels=labels.to(device)\n","        pred=model(imgs)\n","        loss=loss_fn(pred,labels)\n","        track_loss+=loss.item()\n","        num_correct+=(torch.argmax(pred,dim=1)==labels).type(torch.float).sum().item()\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if i%100==0:\n","            running_loss=round(track_loss/(i+1),2)\n","            running_acc=round((num_correct/((i+1)*batch_size))*100,2)\n","            print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n","            \n","    epoch_loss=track_loss/len(dataloader) #can be slightly inaccurate\n","    epoch_acc=(num_correct/len(dataloader.dataset))*100    \n","    return round(epoch_loss,2), round(epoch_acc,2)\n","\n","def eval_one_epoch(dataloader, model,loss_fn):\n","    model.eval()\n","    track_loss=0\n","    num_correct=0\n","    with torch.no_grad():\n","        for i, (imgs, labels) in enumerate(dataloader):\n","            imgs=torch.reshape(imgs,shape=[-1,784]).to(device)\n","            labels=labels.to(device)\n","            pred=model(imgs)\n","            loss=loss_fn(pred,labels)\n","            track_loss+=loss.item()\n","            num_correct+=(torch.argmax(pred,dim=1)==labels).type(torch.float).sum().item()\n","\n","            if i%100==0:\n","                running_loss=round(track_loss/(i+1),2)\n","                running_acc=round((num_correct/((i+1)*batch_size))*100,2)\n","                print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n","\n","    epoch_loss=track_loss/len(dataloader) #can be slightly inaccurate\n","    epoch_acc=(num_correct/len(dataloader.dataset))*100    \n","    return round(epoch_loss,2), round(epoch_acc,2)\n","\n","model=MNISTNN()\n","model=model.to(device)\n","loss_fn=nn.CrossEntropyLoss()\n","lr=0.001\n","#optimizer=torch.optim.SGD(params=model.parameters(), lr=lr)\n","optimizer=torch.optim.Adam(params=model.parameters(), lr=lr)\n","n_epochs=30\n","\n","for i in range(n_epochs):\n","    print(\"Epoch No:\",i+1)\n","    train_epoch_loss, train_epoch_acc=train_one_epoch(train_dl,model,loss_fn,optimizer)\n","    val_epoch_loss, val_epoch_acc=eval_one_epoch(test_dl,model,loss_fn)\n","    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n","    print(\"Inference:\", \"Epoch Loss:\", val_epoch_loss, \"Epoch Accuracy:\", val_epoch_acc)\n","    print(\"--------------------------------------------------\")\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30635,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3.11.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}}},"nbformat":4,"nbformat_minor":5}
